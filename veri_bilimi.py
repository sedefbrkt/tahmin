# -*- coding: utf-8 -*-
"""veri bilimi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h0r6tlFN3-5iGbTIk0FASklsT6gHaLHl
"""

import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeRegressor

!gdown --id 18_lVTYLcmJi-9EQmOcyTFcwB4Nthu6K2

# Veri setini yükle
dataset = pd.read_csv('heart.csv', encoding='ISO-8859-1')

#veri setinin boyutu
dataset.shape

#veri seti hakkında bilgi
dataset.info()

#genel özellikleri
dataset

#boş veri var mı?
dataset.isnull().sum()

# tekrar eden veri var mı?
duplicated_rows = dataset[dataset.duplicated()]
print(duplicated_rows)

# "dataset" adlı bir veri kümesindeki tekrarlanan satırları kaldırmak için kullanılır.
#"keep" parametresi, hangi tekrarlanan satırların korunacağını belirlemek için kullanılır.
#"keep='first'" seçeneği, ilk tekrarlanan satırın korunacağı anlamına gelir.
# "inplace=True" seçeneği, veri kümesinin doğrudan değiştirileceği anlamına gelir.
# Bu kodun kullanılması, veri kümesindeki tekrarlanan satırların kaldırılmasını ve veri kümesinin güncellenmesini sağlar.
# Veri kümesinin güncellenmiş hali, "inplace=True" seçeneğinin kullanılmasıyla doğrudan değiştirilir.
dataset.drop_duplicates(keep='first',inplace=True)

# veri setinin yeniden düzelenlenmiş hali
dataset

#dataset" adlı bir veri kümesinin istatistiksel özetini (summary statistics) döndürür.
# Bu özet, veri kümesindeki sayısal sütunlar için temel istatistiksel bilgileri sağlar.
# Bu bilgiler arasında ortalama, standart sapma, minimum ve maksimum değerler, çeyreklikler (25%, 50%, 75%) ve veri sayısı yer alır.
dataset.describe()

#Korelasyon matrisi, her bir sütunun diğer sütunlarla olan ilişkisini gösterir.
#Korelasyon matrisi, -1 ile 1 arasında değerler alır. 1'e yakın değerler, iki sütun arasında pozitif bir ilişki olduğunu gösterirken,
#-1'e yakın değerler negatif bir ilişki olduğunu gösterir.
# 0'a yakın değerler ise iki sütun arasında herhangi bir ilişki olmadığını gösterir.

corr = dataset.corr()
corr

# Bu kodlar, bir veri setindeki değişkenler arasındaki ilişkiyi görselleştirmek için kullanılır.
# plt.subplots(figsize=(20,15)) kodu, grafiğin boyutunu belirler.
#sns.heatmap(corr,annot=True) kodu ise, bir korelasyon matrisini alır
#ve bu matristeki değişkenler arasındaki ilişkiyi bir renk skalası kullanarak gösterir.
#En sıcak renkler (örneğin kırmızı), pozitif bir korelasyonu temsil ederken,
# en soğuk renkler (örneğin mavi), negatif bir korelasyonu temsil eder.
#Beyaz renk ise, değişkenler arasında bir korelasyon olmadığını gösterir.

import seaborn as sns
import matplotlib.pyplot as plt

plt.subplots(figsize=(20,15))
sns.heatmap(corr, annot=True)

#veri kümesinin histogramını çizmek için kullanılır.
#bins argümanı, histogramda kullanılacak çubuk sayısını belirlerken,
#figsize argümanı ise çizilen grafiğin boyutunu belirler.
#plt.show() komutu ise grafiği görüntüler.


dataset.hist(bins=20, figsize=(35, 19))
plt.show()

mean_Age = dataset["age"].mean()
dataset['age'] = dataset['age'].mask(dataset['age'] < 30, mean_Age)
dataset["age"].hist()

mean_RestbloodPr = dataset["trtbps"].mean()
dataset['trtbps'] = dataset['trtbps'].mask(dataset['trtbps'] > 180, mean_RestbloodPr)

dataset["trtbps"].hist()

mean_Chol = dataset["chol"].mean()
dataset['chol'] = dataset['chol'].mask(dataset['chol'] >= 370, mean_Chol)

dataset["chol"].hist()

mean_MaxHeartRate = dataset["thalachh"].mean()
dataset['thalachh'] = dataset['thalachh'].mask(dataset['thalachh'] < 90, mean_MaxHeartRate)

dataset["thalachh"].hist()

mean_oldpeak = dataset["oldpeak"].mean()
dataset['oldpeak'] = dataset['oldpeak'].mask(dataset['oldpeak'] >= 5, mean_oldpeak)
dataset["oldpeak"].hist()

dataset = dataset.drop(["fbs"],axis=1)

dataset.hist(bins=20, figsize=(35, 19))
plt.show()

corr = dataset.corr()
corr

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
plt.subplots(figsize=(20,15))
sns.heatmap(corr,annot=True)

#egitim ve test veri setini ayır
from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(
    dataset, test_size=0.2, random_state=1)

#Etiket Verisinin Diğer Veriden Ayrılması
 #lk olarak, "train_set" ve "test_set" veri kümelerinden "output" sütunu ayrılarak, bunlar ayrı değişkenlere atanmıştır:
 #"train_set_labels" ve "test_set_labels".
 #Daha sonra, "train_set" ve "test_set" veri kümelerinden "output" sütunu kaldırılmıştır,
# böylece geriye kalan sütunlar modelin öğrenmesi gereken özellikleri içermektedir.
train_set_labels = train_set["output"].copy()
train_set = train_set.drop("output", axis=1)

test_set_labels = test_set["output"].copy()
test_set = test_set.drop("output", axis=1)

from sklearn.preprocessing import StandardScaler as Scaler

# StandardScaler nesnesi oluşturma
scaler = Scaler()

# Eğitim veri kümesini ölçeklendirme
#fit() yöntemi, eğitim veri kümesindeki özelliklerin ortalamasını ve standart sapmasını hesaplar.
scaler.fit(train_set)
train_set_scaled = scaler.transform(train_set)

# Test veri kümesini ölçeklendirme
#Bu işlem, verilerin farklı ölçeklerde olması durumunda
#modelin yanlış sonuçlar üretmesini önlemeye yardımcı olur.
test_set_scaled = scaler.transform(test_set)

# ölçeklendirilmiş eğitim veri kümesini bir Pandas veri çerçevesine dönüştürür
# ilk beş satırını gösterir
# verilerin doğru şekilde ölçeklendirilip ölçeklendirilmediğini kontrol etmek için kullanılabilir.
dataset = pd.DataFrame(data=train_set_scaled)
dataset.head()

models = []
models.append(('LR', LogisticRegression()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('SVC', SVC()))
models.append(('RFC', RandomForestClassifier()))
models.append(('DTR', DecisionTreeRegressor()))

# Rastgele sayı üretmek için tekrarlanabilirlik için rastgele değeri belirleme
seed = 7

# Sonuçları depolamak ve model adlarını saklamak için boş listeler oluşturma
results = []
names = []

# Ölçeklendirilmiş eğitim kümesi özelliklerini ve etiketlerini sırasıyla X ve Y değişkenlerine atama
X = train_set_scaled
Y = train_set_labels

from sklearn import model_selection

for name, model in models:
    kfold = model_selection.KFold(shuffle=True, n_splits=20, random_state=seed)
    cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)

# GridSearchCV ve RandomizedSearchCV modülleri sklearn.model_selection paketinde yer alır
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Arama yapılacak hiperparametrelerin farklı değerleri param_grid sözlüğünde belirtilir
param_grid = {
    'C': [1.0, 10.0, 50.0],
    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],
    'shrinking': [True, False],
    'gamma': ['auto', 1, 0.1],
    'coef0': [0.0, 0.1, 0.5]
}

# Model nesnesi oluşturma
model_svc = SVC()

# RandomizedSearchCV sınıfından bir nesne oluşturma
# model_svc: kullanılacak model
# param_grid: arama yapılacak hiperparametrelerin farklı değerleri
# cv: çapraz doğrulama sayısı
# scoring: performans ölçütü
grid_search = RandomizedSearchCV(
    model_svc, param_grid, cv=5, scoring='accuracy')

# RandomizedSearchCV nesnesi üzerinde fit() metodu çağrılarak arama işlemi yapılır
# train_set_scaled: ölçeklendirilmiş eğitim veri kümesi
# train_set_labels: eğitim veri kümesindeki hedef sınıf etiketleri
grid_search.fit(train_set_scaled, train_set_labels)

#Ulaşılan En Yüksek Değer:
grid_search.best_score_

#hiperparametre optimizasyonu sonucunda en iyi modeli seçmek için kullanılır
svc = grid_search.best_estimator_

#svc adlı bir makine öğrenimi modelinin, test_set_scaled adlı test veri kümesindeki özelliklerin tahminlerini (predict) yapmasını sağlar
#sonuçları predictions değişkenine atar.
predictions =  svc.predict(test_set_scaled)

#Sklearn kütüphanesindeki metrics modülünden confusion_matrix fonksiyonunu kullanarak bir karışıklık matrisi oluşturur
# ve seaborn kütüphanesindeki heatmap fonksiyonunu kullanarak matrisi ısı haritası olarak görselleştirir.
from sklearn import metrics
confMatrix = metrics.confusion_matrix(test_set_labels,predictions)
import seaborn as sns
sns.heatmap(confMatrix,annot=True)

# grid_search nesnesinin best_estimator_ özelliği, en iyi sonuç veren modeli içerir
svc = grid_search.best_estimator_

# Eğitim ve test setlerini birleştirme
X = np.append(train_set_scaled, test_set_scaled, axis=0)
Y = np.append(train_set_labels, test_set_labels, axis=0)

# SVC modelini birleştirilmiş veri kümesinde eğitme
svc.fit(X, Y)

new_df = pd.DataFrame([[55,1,1,130,210,0,1,155,0,1.5,1,2]])
new_df_scaled = scaler.transform(new_df)
#Ölçeklendirme Yapılmıştır.

prediction = svc.predict(new_df_scaled)

prediction

# Verileri bir DataFrame'e yükleme
df = pd.read_csv('heart.csv')

# Kalp hastalığına sahip kişi sayısını hesaplama
num_people_with_heart_disease = df['output'].sum()

print("Toplam kalp hastalığına sahip kişi sayısı:", num_people_with_heart_disease)

# Kalp hastalığına sahip olan ve olmayan kişilerin yaş ortalamalarını hesaplama
mean_age_with_heart_disease = df[df['output'] == 1]['age'].mean()
mean_age_without_heart_disease = df[df['output'] == 0]['age'].mean()

print("Kalp hastalığına sahip olanların yaş ortalaması:", mean_age_with_heart_disease)
print("Kalp hastalığına sahip olmayanların yaş ortalaması:", mean_age_without_heart_disease)

dataset=pd.read_csv("heart.csv")
# Cinsiyet dağılımını hesaplama
gender_counts = dataset['sex'].value_counts()

# Erkekleri mavi, kadınları turuncu renk kullanarak cinsiyet dağılımını görselleştirme
colors = ['tab:blue', 'tab:orange']
labels = ['Erkek', 'Kadın']
plt.pie(gender_counts, labels=labels, colors=colors, autopct='%1.1f%%')
plt.title('Cinsiyet Dağılımı')

# Erkeklerin ve kadınların sayılarını grafikte gösterme
for i, gender_count in enumerate(gender_counts):
    plt.text(-0.4 + i*0.8, -1.2, str(gender_count), color='white', fontweight='bold', fontsize=16)

plt.show()

dataset.columns = ["Age","Gender","ChestPainTp","RestbloodPr","Chol","Fa_bloodSu","rest_ecg","MaxHeartRate","Ex_In_An","oldpeak","slope","NumMajVest","ThallTest","output"]

kategorik=["Gender","ChestPainTp","Fa_bloodSu","rest_ecg","Ex_In_An","slope","NumMajVest","ThallTest","output"]

df_kategorik=dataset.loc[:,kategorik]

df_kategorik

import seaborn as sns
import matplotlib.pyplot as plt

df_hasta = df_kategorik[df_kategorik["output"] == 1]

for i in df_kategorik:
    plt.figure()
    ax = sns.countplot(x=i, data=df_kategorik, hue="output")
    plt.title(i)

    for p in ax.patches:
        ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', xytext=(0, 10), textcoords='offset points')

df_hasta = df_kategorik[df_kategorik["output"] == 1]

for i in df_hasta:
    plt.figure()
    ax = sns.countplot(x=i, data=df_hasta)
    plt.title(i + " - Hasta")

    for p in ax.patches:
        ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', xytext=(0, 10), textcoords='offset points')

sayisal=[ "Age","RestbloodPr","Chol","MaxHeartRate","oldpeak","output"]

df_sayisal=dataset.loc[:,sayisal]

# "output" değişkeni 1 olan gözlemleri içeren bir DataFrame oluşturun
df_hasta = df_sayisal[df_sayisal["output"] == 1]

# Gruplama kategorilerini tanımlayın
gruplamalar = {
    "Age": [10, 30, 50, 70,90, 100],  # Yaş aralıkları
    "RestbloodPr": [80, 120, 140, 160, 200,240],  # Dinlenme kan basıncı aralıkları
    "Chol": [100, 200, 240, 280, 320, 1000],  # Kolesterol aralıkları
    "MaxHeartRate": [0, 100, 150, 200, 250, 300],  # Maksimum kalp atış hızı aralıkları
    "oldpeak": [-1,0, 1, 2, 3, 4, 6,7]  # ST segment depresyonu aralıkları
}

# Her bir sayısal değişken için ayrı bir grafik çizdirin
for column in gruplamalar:
    fig, ax = plt.subplots(figsize=(8, 6))

    # Gruplama kategorilerini kullanarak veriyi gruplayın
    df_grouped = df_hasta.groupby(pd.cut(df_hasta[column], bins=gruplamalar[column])).size()

    # Grafik çizimini gerçekleştirin
    df_grouped.plot(kind='bar', ax=ax)
    for p in ax.patches:
        ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', xytext=(0, 10), textcoords='offset points')


    ax.set_title("Hasta Olanların " + column + " Değerleri")
    ax.set_xlabel(column)
    ax.set_ylabel("Sınıf Frekansı")
    plt.xticks(rotation=45)
    plt.show()

df_gender = df.groupby(["sex", "output"]).size().reset_index(name="count")

display(df_gender)
df_gender.sum()

df_cp = df.groupby(["cp", "output"]).size().reset_index(name="count")

display(df_cp)
df_cp.sum()

df_fbs = df.groupby(["fbs", "output"]).size().reset_index(name="count")

display(df_fbs)
df_fbs.sum()

df_restecg = df.groupby(["restecg", "output"]).size().reset_index(name="count")

display(df_restecg)
df_restecg.sum()

df_exng	 = df.groupby(["exng", "output"]).size().reset_index(name="count")

display(df_exng	)
df_exng.sum()

df_slp= df.groupby(["slp", "output"]).size().reset_index(name="count")

display(df_slp)
df_slp.sum()

df_caa = df.groupby(["caa", "output"]).size().reset_index(name="count")

display(df_caa	)
df_caa.sum()

# Kümelenme yapılacak sayısal özellikleri belirleyin
sayisal = ["age"]

# Yaş aralıkları
yas_araliklari = [10, 30, 50, 70, 90, 110]

# Yaşları belirtilen aralıklara göre kategorilere ayırma
df["age_group"] = pd.cut(df["age"], bins=yas_araliklari)

# Kümelenmiş veri çerçevesi oluşturma
df_kumelenmis = df.groupby(["age_group", "output"]).size().reset_index(name="count")

# Sonucu gösterme
display(df_kumelenmis)
print("Toplam Count:", df_kumelenmis["count"].sum())

# Kümelenme yapılacak sayısal özelliği belirleyin
sayisal = ["trtbps"]

# Kan basıncı (RestbloodPr) değeri aralıkları
trtbps_araliklari = [80, 120, 160, 200, 240]

# RestbloodPr özelliğini belirtilen aralıklara göre kategorilere ayırma
df["RestbloodPr_group"] = pd.cut(df["trtbps"], bins=trtbps_araliklari)

# Kümelenmiş veri çerçevesi oluşturma
df_kumelenmis = df.groupby(["RestbloodPr_group", "output"]).size().reset_index(name="count")

# Sonucu gösterme
display(df_kumelenmis)
print("Toplam Count:", df_kumelenmis["count"].sum())

# Kümelenme yapılacak sayısal özelliği belirleyin
sayisal = ["Chol"]

# Chol değerleri aralıkları
chol_araliklari = [100, 200, 240, 280, 320, 1000]

# Chol özelliğini belirtilen aralıklara göre kategorilere ayırma
dataset["Chol_group"] = pd.cut(dataset["Chol"], bins=chol_araliklari)

# Kümelenmiş veri çerçevesi oluşturma
df_kumelenmis = dataset.groupby(["Chol_group", "output"]).size().reset_index(name="count")

# Sonucu gösterme
display(df_kumelenmis)
print("Toplam Count:", df_kumelenmis["count"].sum())

# Kümelenme yapılacak sayısal özelliği belirleyin
sayisal = ["MaxHeartRate"]

# Maksimum Kalp Atış Hızı aralıkları
heart_rate_araliklari = [30, 100, 150, 200, 250, 300]

# MaxHeartRate özelliğini belirtilen aralıklara göre kategorilere ayırma
dataset["HeartRate_group"] = pd.cut(dataset["MaxHeartRate"], bins=heart_rate_araliklari)

# Kümelenmiş veri çerçevesi oluşturma
df_kumelenmis = dataset.groupby(["HeartRate_group", "output"]).size().reset_index(name="count")

# Sonucu gösterme
display(df_kumelenmis)
df_kumelenmis.sum()

# Kümelenme yapılacak sayısal özelliği belirleyin
sayisal = ["oldpeak"]

# Oldpeak değerleri aralıkları
oldpeak_araliklari = [-1,0, 1, 2, 3, 4, 6,7]

# Oldpeak özelliğini belirtilen aralıklara göre kategorilere ayırma
dataset["oldpeak_group"] = pd.cut(dataset["oldpeak"], bins=oldpeak_araliklari)

# Kümelenmiş veri çerçevesi oluşturma
df_kumelenmis = dataset.groupby(["oldpeak_group", "output"]).size().reset_index(name="count")

# Sonucu gösterme
display(df_kumelenmis)
df_kumelenmis.sum()

import pandas as pd

# Veri setini yükleme
df = pd.read_csv("heart.csv")

# Cinsiyete göre özellikleri gruplama
df_grouped = df.groupby("sex").agg({
    "age": "mean",
    "cp": "mean",
    "trtbps": "mean",
    "chol": "mean",
    "fbs": "mean",
    "restecg": "mean",
    "thalachh": "mean",
    "exng": "mean",
    "oldpeak": "mean",
    "slp": "mean",
    "caa": "mean",
    "thall": "mean",
    "output": "sum"
}).reset_index()

# Sonucu gösterme
display(df_grouped)

# Gruplama kategorilerini tanımlayın
gruplamalar = {
    "Age": [10, 30, 50, 70,90, 100],  # Yaş aralıkları
    "RestbloodPr": [80, 120, 140, 160, 200,240],  # Dinlenme kan basıncı aralıkları
    "Chol": [100, 200, 240, 280, 320, 1000],  # Kolesterol aralıkları
    "MaxHeartRate": [0, 100, 150, 200, 250, 300],  # Maksimum kalp atış hızı aralıkları
    "oldpeak": [-1,0, 1, 2, 3, 4, 6,7]  # ST segment depresyonu aralıkları
}

# Her bir sayısal değişken için ayrı bir grafik çizdirin
for column in gruplamalar:
    fig, ax = plt.subplots(figsize=(8, 6))

    # Gruplama kategorilerini kullanarak veriyi gruplayın
    df_grouped_hasta = df_hasta.groupby(pd.cut(df_hasta[column], bins=gruplamalar[column])).size()
    df_grouped_saglikli = df_sayisal[df_sayisal["output"] == 0].groupby(pd.cut(df_sayisal[df_sayisal["output"] == 0][column], bins=gruplamalar[column])).size()

    # Grafik çizimini gerçekleştirin
    ax.bar(df_grouped_hasta.index.astype(str), df_grouped_hasta.values, label="Hasta")
    ax.bar(df_grouped_saglikli.index.astype(str), df_grouped_saglikli.values, label="Sağlıklı")
    for p in ax.patches:
        ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', xytext=(0, 10), textcoords='offset points')

    ax.set_title(column + " Değerlerine Göre Hasta ve Sağlıklı Sayısı")
    ax.set_xlabel(column)
    ax.set_ylabel("Sınıf Frekansı")
    plt.xticks(rotation=45)
    plt.legend()
    plt.show()